# 📚 每日论文速递 - 2026-01-26

**研究方向**: Causal LLM
**筛选条件**: 顶会顶刊 (CCF-A / CORE A* / CORE A)
**论文数量**: 3

---

## 1. CLadder: Assessing Causal Reasoning in Language Models

**基本信息**
- 作者: Zhijing Jin, Yuen Chen, Felix Leeb, Luigi Gresele, Ojasv Kamal, Zhiheng Lyu, Kevin Blin, Fernando Gonzalez Adauto, Max Kleiman-Weiner, Mrinmaya Sachan, Bernhard Schölkopf
- 发布: 2023-12-07
- 会议/期刊: NeurIPS 2023 (CCF-A)
- 引用数: 94 📈
- arXiv: [2312.04350](https://arxiv.org/abs/2312.04350)

**主要贡献**
本文提出了 CLadder，一个评估大型语言模型因果推理能力的基准数据集。该数据集包含 10,000 个样本，涵盖关联性、干预性和反事实三个层次的因果问题，基于 Judea Pearl 提出的"因果推理引擎"理论构建。

**方法**
- 基于因果图和查询集合构建符号化问题
- 通过因果推理引擎获取标准答案
- 提出专门的思维链提示策略 CausalCoT
- 覆盖 Pearl 因果层级的三个层次

**实验**
在多个 LLM 上进行评估，结果表明因果推理对当前 LLM 仍是一个重大挑战。即使使用 CausalCoT 提示策略，模型在需要严格因果推理的问题上仍表现不佳。

**结论**
当前 LLM 缺乏真正的因果推理能力，主要依赖于训练数据中的表面关联而非深层因果理解。该基准为未来因果推理研究提供了重要评估工具。

**资源**
- 数据集: https://huggingface.co/datasets/causalNLP/cladder
- 代码: https://github.com/causalNLP/cladder

---

## 2. Can Large Language Models Infer Causation from Correlation?

**基本信息**
- 作者: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona Diab, Bernhard Schölkopf
- 发布: 2023-06-09
- 会议/期刊: ICLR 2024 (CCF-A)
- 引用数: ~80 📈
- arXiv: [2306.05836](https://arxiv.org/abs/2306.05836)

**主要贡献**
提出 Corr2Cause，首个测试 LLM 纯因果推理技能的基准数据集。该任务要求模型根据一组相关性陈述确定变量之间的因果关系。

**方法**
- 构建超过 200,000 个样本的大规模数据集
- 评估 17 个现有 LLM 的因果推理能力
- 测试模型从相关性推断因果性的能力
- 研究微调对泛化能力的影响

**实验**
实验揭示了 LLM 在因果推理方面的关键缺陷：
- 模型在任务上几乎达到随机水平的性能
- 微调虽有改善，但模型仍难以泛化
- 只能在同分布设置下进行因果推理
- 当变量名或表述方式改变时性能大幅下降

**结论**
LLM 在纯因果推理任务上表现不佳，表明它们缺乏真正的因果推理能力。这为未来提升 LLM 因果能力的研究指明了方向。

**资源**
- 代码: https://github.com/causalNLP/corr2cause

---

## 3. Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting

**基本信息**
- 作者: Wei Chen, Jiahao Zhang, Haipeng Zhu, Boyan Xu, Zhifeng Hao, Keli Zhang, Junjian Ye, Ruichu Cai
- 发布: 2025-05-30
- 会议/期刊: IJCAI 2025 (CCF-A)
- 引用数: 3 📈
- arXiv: [2505.24710](https://arxiv.org/abs/2505.24710)

**主要贡献**
提出 Causal-aware LLMs，将结构因果模型 (SCM) 集成到 LLM 决策过程中，通过"学习-适应-行动"范式增强决策能力。

**方法**
采用三阶段范式：
1. **学习阶段**: 利用 LLM 提取环境特定的因果实体及其因果关系，初始化结构因果模型
2. **适应阶段**: 通过因果干预，利用环境反馈更新结构因果模型
3. **行动阶段**: 利用结构化因果知识，通过强化学习代理进行更高效的策略制定

**实验**
在 Crafter 环境的 22 个任务上进行评估：
- 显著提升了环境理解能力
- 提高了决策效率
- 展示了因果知识在复杂任务中的价值

**结论**
将因果建模与 LLM 结合是提升 AI 决策能力的有效途径。该方法弥补了预训练模型在推理能力和环境适应性方面的不足。

---

## 相关已记录论文

以下论文已在之前的搜索中记录，本次更新跳过：

| 论文 | 会议 | 引用数 |
|-----|------|-------|
| Unveiling Causal Reasoning in LLMs | NeurIPS 2025 | 54 |
| LLMs and Causal Inference: A Survey | arXiv | 28 |
| Causal Inference with LLM: A Survey | NAACL | 23 |
| LLMs for Causal Discovery | IJCAI 2024 | 14 |
| Failure Modes of LLMs for Causal Reasoning | arXiv | 8 |
| Counterfactual Causal Inference in NL | arXiv | 7 |
| Causal Reflection with Language Models | arXiv | 1 |

---

*Generated by paper-daily skill*
